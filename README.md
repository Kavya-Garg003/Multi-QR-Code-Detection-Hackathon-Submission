# ğŸ“Œ Multi-QR Code Detection â€“ Hackathon Submission

This repository contains code for the **Multi-QR Code Recognition Challenge**.
The task is to **detect all QR codes** on medicine pack images, and optionally **decode + classify** them.

---

## ğŸ“‚ Repository Structure

```
multiqr-hackathon/
â”‚
â”œâ”€â”€ README.md                 # Setup & usage instructions
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ train.py                  # Training script
â”œâ”€â”€ infer.py                  # Inference (images â†’ JSON output)
â”œâ”€â”€ evaluate.py               # Simple evaluation (optional)
â”œâ”€â”€ hyp_qr.yaml               # Hyperparameters + augmentations
â”‚
â”œâ”€â”€ data/                     # Placeholder (dataset not committed)
â”‚   â””â”€â”€ demo_images/          # Small sample for demo
â”‚
â”œâ”€â”€ outputs/                  
â”‚   â”œâ”€â”€ submission_detection_1.json   # Stage 1 submission
â”‚   â””â”€â”€ submission_decoding_2.json    # Stage 2 (bonus)
â”‚
â””â”€â”€ src/                      # Core code, utils, loaders
    â”œâ”€â”€ models/
    â”œâ”€â”€ datasets/
    â”œâ”€â”€ utils/
    â””â”€â”€ __init__.py
```

---

## âš™ï¸ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/multiqr-hackathon.git
cd multiqr-hackathon
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

Contents of `requirements.txt`:

```
ultralytics==8.3.0
opencv-python
numpy
pyyaml
```

---

## ğŸ“¦ Dataset Preparation

1. **Upload dataset to Google Drive or local path**.
   Structure must be YOLO-format:

```
datasets/qr/
   â”œâ”€â”€ images/
   â”‚    â”œâ”€â”€ train/
   â”‚    â””â”€â”€ val/          # optional (can reuse train if no val set)
   â””â”€â”€ labels/
        â”œâ”€â”€ train/
        â””â”€â”€ val/
   â””â”€â”€ data.yaml
```

2. **Example `data.yaml`**:

```yaml
train: /content/drive/MyDrive/QR_dataset/datasets/qr/images/train
val: /content/drive/MyDrive/QR_dataset/datasets/qr/images/val

nc: 1
names: ["qr"]
```

If no validation split is available, point both `train` and `val` to the same folder, or set `val=False` in training.

---

## ğŸš€ Training

Run the training script:

```bash
python train.py \
  --data /content/drive/MyDrive/QR_dataset/datasets/qr/data.yaml \
  --model yolov8m.pt \
  --epochs 100 \
  --imgsz 960 \
  --batch 8 \
  --hyp hyp_qr.yaml
```

This will save results to:

```
/content/runs/detect/qr_detector_aug/
```

Inside youâ€™ll find:

* `weights/best.pt` (final checkpoint)
* `results.png` (training curves)
* `results.csv` (raw metrics)

---

## ğŸ” Inference

Run detection + decoding:

```bash
python infer.py \
  --weights /content/runs/detect/qr_detector_aug/weights/best.pt \
  --input data/demo_images \
  --output outputs
```

This generates:

* `outputs/submission_detection_1.json` âœ… (Stage 1)
* `outputs/submission_decoding_2.json` âœ… (Stage 2 bonus)

Format example:

```json
[
  {
    "image_id": "img001.jpg",
    "qrs": [
      {"bbox": [10, 20, 100, 150], "value": "B12345", "type": "batch"},
      {"bbox": [200, 50, 300, 180], "value": "MFR56789", "type": "manufacturer"}
    ]
  }
]
```

---

## ğŸ“Š Evaluation (optional)

You can quickly check how many QRs were detected:

```bash
python evaluate.py --pred outputs/submission_detection_1.json
```

---

## ğŸ“Œ Notes

* The solution is **fully runnable & reproducible**.
* No external APIs are used.
* Supports augmentation, tilted/blurred/occluded QR codes.
* Efficient inference â†’ lighter/faster models rank higher.

---

## ğŸ† Submission Checklist

* [x] `submission_detection_1.json` (Stage 1)
* [x] `submission_decoding_2.json` (Stage 2, bonus)
* [x] Complete runnable repo with `README.md`, `train.py`, `infer.py`, `evaluate.py`
* [x] Instructions for dataset, training, inference

---

